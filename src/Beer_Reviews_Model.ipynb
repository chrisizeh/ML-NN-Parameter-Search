{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdeff493",
   "metadata": {},
   "source": [
    "# Load Preprocessed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4215c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_bag = pd.read_csv('../data/beer_target_valid.csv')\n",
    "y_valid = pd.read_csv('../data/beer_valid.csv')\n",
    "X_train_bag = pd.read_csv('../data/beer_train.csv')\n",
    "y_train = pd.read_csv('../data/beer_target_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2757d3",
   "metadata": {},
   "source": [
    "# Find Solution for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4afda021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a7ff094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ttrain, X_test, y_ttrain, y_test = train_test_split(X_train_bag.values, y_train.values, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "65e8e5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.5 4.  3.5 4.5 4.  5.5 1.  1. ]\n",
      " [4.  3.5 4.  4.  3.5 5.5 1.  1. ]\n",
      " [4.5 3.5 3.5 4.  3.5 5.5 1.  1. ]\n",
      " [4.  3.5 4.  4.  4.  5.5 1.  1. ]\n",
      " [4.  3.5 4.5 4.  4.  5.5 1.  1. ]\n",
      " [4.5 4.  4.  4.5 4.5 7.4 0.  0. ]\n",
      " [3.5 4.  3.5 3.5 4.  5.5 1.  1. ]\n",
      " [3.  3.5 4.  3.5 2.5 5.5 1.  1. ]\n",
      " [5.  4.  4.5 4.5 4.  5.5 1.  1. ]\n",
      " [4.  3.5 4.  3.5 4.  5.5 1.  1. ]\n",
      " [4.  4.  4.5 4.  4.  5.5 1.  1. ]\n",
      " [4.5 5.  4.5 4.5 4.  5.5 1.  1. ]\n",
      " [3.5 3.5 3.5 4.  3.5 5.5 1.  1. ]\n",
      " [4.  4.  4.  4.  3.5 5.5 1.  1. ]\n",
      " [4.  4.  4.  4.  4.  5.5 1.  1. ]\n",
      " [5.  4.  3.5 4.  4.  5.5 1.  1. ]\n",
      " [4.  4.  4.  4.  4.  5.5 1.  1. ]\n",
      " [3.5 3.5 4.  4.  3.5 5.5 1.  1. ]\n",
      " [3.5 3.5 3.5 4.  3.5 5.5 1.  1. ]\n",
      " [4.  4.  3.5 4.  4.  7.4 0.  0. ]\n",
      " [4.5 4.5 4.  4.  4.  7.4 0.  0. ]\n",
      " [3.  2.5 3.  3.  3.  6.2 0.  0. ]\n",
      " [4.  4.5 4.  4.  4.5 7.4 0.  0. ]\n",
      " [4.  4.  4.5 4.  4.  7.4 0.  0. ]\n",
      " [4.  4.  3.5 4.5 4.  7.4 0.  0. ]\n",
      " [3.  3.5 3.5 3.  3.5 4.7 0.  0. ]\n",
      " [4.  3.  4.  4.  4.  5.5 1.  1. ]\n",
      " [4.5 4.5 4.5 4.  4.  5.5 1.  1. ]\n",
      " [5.  5.  3.5 3.5 5.  7.4 0.  0. ]\n",
      " [3.5 3.5 4.5 4.  3.  5.5 1.  1. ]\n",
      " [4.5 3.5 3.  4.  4.  5.5 1.  1. ]\n",
      " [4.  4.5 3.5 3.5 4.  7.4 0.  0. ]\n",
      " [3.5 4.  5.  3.5 4.  5.5 1.  1. ]\n",
      " [4.  4.5 4.  4.  4.5 7.7 0.  0. ]\n",
      " [4.  4.5 3.  2.5 3.  4.7 0.  0. ]\n",
      " [4.  4.  4.5 4.  4.  5.5 1.  1. ]\n",
      " [4.  4.5 4.  3.5 4.  7.4 0.  0. ]\n",
      " [4.  4.  3.  4.  4.  7.4 0.  0. ]\n",
      " [3.  4.  3.5 3.5 3.  5.5 1.  1. ]\n",
      " [4.  4.  4.5 4.  4.  5.5 1.  1. ]\n",
      " [4.  4.  4.  3.5 4.  5.5 1.  1. ]\n",
      " [3.5 4.  4.  3.5 3.5 5.5 1.  1. ]\n",
      " [4.  3.5 4.  4.  4.  5.5 1.  1. ]\n",
      " [4.  4.  4.  3.  3.5 5.5 1.  1. ]\n",
      " [3.5 4.  3.  3.  4.  4.7 0.  0. ]\n",
      " [4.  4.  4.  3.5 4.5 5.5 1.  1. ]\n",
      " [4.  4.  3.5 4.  4.  7.4 0.  0. ]\n",
      " [4.  4.5 4.  4.  4.5 7.4 0.  0. ]\n",
      " [3.5 4.  4.  3.5 3.5 7.4 0.  0. ]\n",
      " [4.  4.  4.  4.  4.  7.4 0.  0. ]\n",
      " [4.  3.  4.  4.  4.  5.6 0.  0. ]\n",
      " [4.5 4.  4.5 4.  4.  5.5 1.  1. ]\n",
      " [3.  2.5 3.  3.  3.  5.5 1.  1. ]\n",
      " [3.  2.5 3.5 2.  3.5 4.7 0.  0. ]\n",
      " [4.5 4.  4.  3.5 4.  5.5 1.  1. ]\n",
      " [3.  3.  4.  4.  3.  5.5 1.  1. ]\n",
      " [4.5 4.  4.  3.5 4.  5.5 1.  1. ]\n",
      " [3.5 3.5 4.  3.5 3.5 5.5 1.  1. ]\n",
      " [4.  3.5 4.  4.  4.  5.5 1.  1. ]\n",
      " [4.5 5.  4.  4.  4.  7.4 0.  0. ]\n",
      " [3.5 3.5 3.5 3.5 4.  5.5 1.  1. ]\n",
      " [4.5 4.5 3.5 4.  4.5 7.4 0.  0. ]\n",
      " [4.  3.5 3.5 4.  4.5 5.5 1.  1. ]\n",
      " [5.  4.  3.5 4.5 4.  5.5 1.  1. ]\n",
      " [5.  4.  4.5 4.  4.  5.5 1.  1. ]\n",
      " [4.  3.5 3.5 3.5 3.5 5.5 1.  1. ]\n",
      " [4.  4.5 4.  4.5 4.  5.5 1.  1. ]\n",
      " [4.  3.5 4.  3.  3.5 7.4 0.  0. ]\n",
      " [4.5 4.  4.  4.  4.  5.5 1.  1. ]\n",
      " [3.  3.  3.5 3.  2.5 5.5 1.  1. ]\n",
      " [4.  3.5 4.  3.  4.  5.5 1.  1. ]\n",
      " [4.  4.  4.  4.  4.  7.4 0.  0. ]\n",
      " [4.  4.  4.5 4.  4.  5.5 1.  1. ]\n",
      " [4.  4.  4.  3.  4.  7.4 0.  0. ]\n",
      " [4.  4.  4.5 4.  3.5 8.1 1.  0. ]\n",
      " [4.  4.5 4.5 4.  3.5 7.4 0.  0. ]\n",
      " [3.  3.  3.5 2.5 3.  5.  0.  0. ]\n",
      " [5.  3.5 4.  4.  5.  5.5 1.  1. ]]\n",
      "[ 1  1  1  1  1 12  1  1  1  1  1  1  1  1  1  1  1  1  1 12 12  5 12 12\n",
      " 12  9  1  1 12  1  1 12  1  0  9  1 12 12  1  1  1  1  1  1  9  1 12 12\n",
      " 12 12  2  1  1  9  1  1  1  1  1 12  1 12  1  1  1  1  1 12  1  1  1 12\n",
      "  1 12  4 12  7  1]\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(X_ttrain)\n",
    "print(y_ttrain)\n",
    "print(y_ttrain.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6e8573",
   "metadata": {},
   "source": [
    "## Build torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1a580683",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.any(np.isnan(X_ttrain))\n",
    "assert not np.any(np.isnan(y_ttrain))\n",
    "assert not np.any(np.isnan(X_test))\n",
    "assert not np.any(np.isnan(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bb1b970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# convert a df to tensor to be used in pytorch\n",
    "def X_to_tensor(df):\n",
    "    return torch.from_numpy(df).float().to(device)\n",
    "\n",
    "def y_to_tensor(df):\n",
    "    return torch.from_numpy(df).long().to(device)\n",
    "\n",
    "X_train_tensor = X_to_tensor(X_ttrain)\n",
    "y_train_tensor = y_to_tensor(y_ttrain)\n",
    "\n",
    "X_test_tensor = X_to_tensor(X_test)\n",
    "y_test_tensor = y_to_tensor(y_test)\n",
    "\n",
    "X_valid_tensor = X_to_tensor(X_valid_bag.values)\n",
    "y_valid_tensor = y_to_tensor(y_valid.values)\n",
    "\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_ds = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "valid_ds = TensorDataset(X_valid_tensor, y_valid_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3ea004d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_ttrain\n",
    "del X_test\n",
    "\n",
    "del y_ttrain\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "46cc9573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 8])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=len(valid_ds))\n",
    "\n",
    "for XX, yy in train_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {XX.shape}\")\n",
    "    print(f\"Shape of y: {yy.shape} {yy.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16463da9",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0c38c825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=250, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=250, out_features=164, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=164, out_features=164, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=164, out_features=104, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(len(train_ds[0][0]), 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250, 164),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(164, 164),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(164, 104)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5300a4",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e95387a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b07e9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    test_loss = 0\n",
    "    for batch, (XX, yy) in enumerate(dataloader):\n",
    "        XX, yy = XX.to(device), yy.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(XX)\n",
    "        loss = loss_fn(pred, yy)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = loss.item()\n",
    "        test_loss += loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            current = (batch + 1) * len(XX)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return test_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7a613680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for XX, yy in dataloader:\n",
    "            XX, yy = XX.to(device), yy.to(device)\n",
    "            pred = model(XX)\n",
    "            test_loss += loss_fn(pred, yy).item()\n",
    "            # correct += (pred.argmax(1) == yy).type(torch.float).sum().item()\n",
    "            correct += f1_score(yy, pred.argmax(1), average='weighted')\n",
    "    test_loss /= num_batches\n",
    "    correct /= num_batches\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "20a02e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.668236  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 40.1%, Avg loss: 3.978080 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.901556  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 40.1%, Avg loss: 2.971987 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.769209  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 40.1%, Avg loss: 1.887615 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.540605  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 40.1%, Avg loss: 1.639313 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.322306  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.618866 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.306880  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 11.1%, Avg loss: 1.643456 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.340725  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 11.1%, Avg loss: 1.650668 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.347639  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 11.1%, Avg loss: 1.638104 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.328176  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 11.1%, Avg loss: 1.625550 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.308263  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 16.9%, Avg loss: 1.619660 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.296968  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 16.9%, Avg loss: 1.616822 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.289516  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 16.9%, Avg loss: 1.612896 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.280652  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 27.2%, Avg loss: 1.609485 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.272499  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 27.2%, Avg loss: 1.605706 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.263965  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 27.2%, Avg loss: 1.600903 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.254229  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 27.2%, Avg loss: 1.596040 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.244397  [   64/   78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.590406 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.233744  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 49.9%, Avg loss: 1.584713 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.223118  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 49.9%, Avg loss: 1.578990 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.212763  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 49.9%, Avg loss: 1.572575 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.201744  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.565788 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.190551  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.559080 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.179472  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 1.551547 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.167630  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.543868 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.155709  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.537421 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.146033  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.530867 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.135171  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.523567 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.123711  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.514976 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.110963  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.506045 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.097782  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.497616 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.085253  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.490570 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.074543  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.479321 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.058759  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.471553 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.047386  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.462335 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.034418  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.451519 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.019444  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.441414 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.004997  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.430762 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.989911  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.419504 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.974060  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.406592 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.956235  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.394699 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.939621  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.382415 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.922575  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.368264 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.903207  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 1.353093 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.882703  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 1.336193 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.860173  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 1.315577 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.833307  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 1.291960 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.802651  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 1.262293 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.764785  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 1.226723 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.719373  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.187528 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.666787  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.168329 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.628050  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.198586 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.631182  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 1.270041 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.673988  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 1.359808 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.737486  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 51.3%, Avg loss: 1.456128 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.810966  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 1.520308 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.861390  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 1.505589 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.847015  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 51.3%, Avg loss: 1.411864 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.768047  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1.287428 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.668016  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 1.208123 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.606350  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.175529 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.580139  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.167600 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.570241  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.167114 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.565113  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.166567 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.560389  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.165094 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.555317  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.164977 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.551020  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.162719 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.545936  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.162747 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.542039  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.161269 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.537549  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.159399 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.533010  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.158436 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.528873  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.156132 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.524265  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.154480 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.520037  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.151662 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.515325  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.150288 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.511398  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.147691 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.506960  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.146547 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.503364  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.144805 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.499505  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.144439 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.496220  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.142556 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.492578  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.141439 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.489176  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.138857 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.485368  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.140334 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.483140  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.138381 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.479629  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.137550 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.476733  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.137795 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.474363  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.134531 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.470549  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.135593 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.468453  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.132774 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.464913  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.133897 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.462900  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.130980 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.459507  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.130624 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.457181  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.130764 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.455024  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.132689 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.453695  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.129659 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.450301  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.131170 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.448763  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.127754 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.445437  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.129528 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.444128  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.124835 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.440439  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.126245 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.439111  [   64/   78]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.125232 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "test_losses = []\n",
    "accs = []\n",
    "\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    losses.append(train(train_dataloader, model, loss_fn, optimizer))\n",
    "    test_loss, acc = test(test_dataloader, model, loss_fn)\n",
    "\n",
    "    accs.append(acc)\n",
    "    test_losses.append(test_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5aec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "plt.plot(range(len(accs)), accs)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.savefig(f\"../results/beer_init_nn_acc.png\", bbox_inches=\"tight\")\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(range(len(losses)), losses, label=\"Training\")\n",
    "plt.plot(range(len(test_losses)), test_losses, label=\"Test\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(f\"../results/beer_init_nn_loss.png\", bbox_inches=\"tight\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c7f8a",
   "metadata": {},
   "source": [
    "Best: 89.5% -> 30 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80978cc",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f2a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model):\n",
    "    num_batches = len(dataloader)\n",
    "    assert num_batches == 1\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for XX, yy in dataloader:\n",
    "            XX, yy = XX.to(device), yy.to(device)\n",
    "            pred = model(XX)\n",
    "            print(classification_report(yy, pred.argmax(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test(valid_dataloader, model, loss_fn))\n",
    "validate(valid_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4567f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del loss_fn\n",
    "del optimizer\n",
    "\n",
    "del train_dataloader\n",
    "del test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c8314",
   "metadata": {},
   "source": [
    "Result for validation set: 90.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d25e66",
   "metadata": {},
   "source": [
    "# Parameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d980415",
   "metadata": {},
   "source": [
    "Parameter to test: Learning Rate, Batch Size, Layer Nodes, Activation Function, Dropout \\\n",
    "Activation Function: relu, sigmoid, linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a0027-83da-4423-b4a2-b4eac4cc1c23",
   "metadata": {},
   "source": [
    "## Shrink Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d899020-ce61-4e8e-a905-caf58b2096ae",
   "metadata": {},
   "source": [
    "Use only 2% of the data for parameter testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4bd534dd-9764-4e96-9faa-2306e7c1b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_train_bag_small, _, y_train_small = train_test_split(X_train_bag, y_train, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f40982ca-6201-42f0-9a20-7e50d4e0e9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_bag_small))\n",
    "print(len(y_train_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "84814142-1299-4a66-9b60-9dc27d06f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ttrain_small, X_test_small, y_ttrain_small, y_test_small = train_test_split(X_train_bag_small.values, y_train_small.values, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "62f8f2e1-fc5c-4614-9278-2eadcbcb95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small_tensor = X_to_tensor(X_ttrain_small)\n",
    "y_train_small_tensor = y_to_tensor(y_ttrain_small)\n",
    "\n",
    "X_test_small_tensor = X_to_tensor(X_test_small)\n",
    "y_test_small_tensor = y_to_tensor(y_test_small)\n",
    "\n",
    "train_small_ds = TensorDataset(X_train_small_tensor, y_train_small_tensor)\n",
    "test_small_ds = TensorDataset(X_test_small_tensor, y_test_small_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1acb003-2d45-449e-8717-70bc279b96eb",
   "metadata": {},
   "source": [
    "## Run Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f4a2d6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e3a0cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d9c0b67a-101e-4e7e-948d-a9ee6cd7fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_func(loc_pred, loc_y):\n",
    "    # return (loc_pred.argmax(1) == loc_y).type(torch.float).sum().item()\n",
    "    return f1_score(loc_y, loc_pred.argmax(1), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "434f5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NNModel import NNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0875ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = [len(train_small_ds[0][0]), 250, 164, 164, 104]\n",
    "nnmodel = NNModel(layer, device, acc_func=acc_func, loss_func=nn.CrossEntropyLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c25dcf-862c-4147-81b7-463f8d1aeea4",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7a2b703f-0b8e-4f0a-bb47-8973bee25b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch: 3\n",
      "Parameter Combination (0.001, 320) with keys ['learning_rate', 'batch_size']\n",
      " Accuracy: 0.0\n",
      "\n",
      "Parameter Combination (0.001, 640) with keys ['learning_rate', 'batch_size']\n",
      " Accuracy: 0.0\n",
      "\n",
      "Early stopping at epoch: 23\n",
      "Parameter Combination (0.001, 1280) with keys ['learning_rate', 'batch_size']\n",
      " Accuracy: 0.0\n",
      "\n",
      "Parameter Combination (0.01, 320) with keys ['learning_rate', 'batch_size']\n",
      " Accuracy: 0.0\n",
      "\n",
      "Parameter Combination (0.01, 640) with keys ['learning_rate', 'batch_size']\n",
      " Accuracy: 0.0\n",
      "\n",
      "Parameter Combination (0.01, 1280) with keys ['learning_rate', 'batch_size']\n",
      " Accuracy: 0.0\n",
      "\n",
      "Early stopping at epoch: 3\n",
      "Parameter Combination (0.05, 320) with keys ['learning_rate', 'batch_size']\n",
      " Accuracy: 0.0\n",
      "\n",
      "Early stopping at epoch: 3\n",
      "Parameter Combination (0.05, 640) with keys ['learning_rate', 'batch_size']\n",
      " Accuracy: 0.0\n",
      "\n",
      "Early stopping at epoch: 4\n",
      "Parameter Combination (0.05, 1280) with keys ['learning_rate', 'batch_size']\n",
      " Accuracy: 0.0\n",
      "\n",
      "Grid search took 0.0 minutes.\n",
      "{'learning_rate': 0.001, 'batch_size': 320}\n"
     ]
    }
   ],
   "source": [
    "test_layer = [[len(train_small_ds[0][0]), 250, 164, 164, 104], [len(train_small_ds[0][0]), 25, 16, 16, 104], [len(train_small_ds[0][0]), 250, 164, 104]]\n",
    "dict_param_1 = {\"learning_rate\": [0.001, 0.01, 0.05], \"batch_size\": [320, 640, 1280]}\n",
    "best, acc = nnmodel.grid_search(dict_param_1, train_small_ds, test_small_ds, epochs=50)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0a9683",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "batch_size should be a positive integer value, but got batch_size=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m nnmodel\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m best[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m dict_param_2 \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m: [nn\u001b[38;5;241m.\u001b[39mReLU, nn\u001b[38;5;241m.\u001b[39mSigmoid, nn\u001b[38;5;241m.\u001b[39mIdentity], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.5\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_layer}\n\u001b[0;32m----> 4\u001b[0m best, acc \u001b[38;5;241m=\u001b[39m \u001b[43mnnmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_param_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_small_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_small_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m best\n",
      "File \u001b[0;32m~/ml/ML-NN-Parameter-Search/src/NNModel.py:131\u001b[0m, in \u001b[0;36mNNModel.grid_search\u001b[0;34m(self, dict_param, train_ds, test_ds, epochs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_comb \u001b[38;5;129;01min\u001b[39;00m iter_params:\n\u001b[1;32m    130\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_params(param_comb, keys)\n\u001b[0;32m--> 131\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(acc \u001b[38;5;241m>\u001b[39m best_acc):\n\u001b[1;32m    133\u001b[0m         best_param \u001b[38;5;241m=\u001b[39m param_comb\n",
      "File \u001b[0;32m~/ml/ML-NN-Parameter-Search/src/NNModel.py:99\u001b[0m, in \u001b[0;36mNNModel.run\u001b[0;34m(self, params, train_ds, test_ds, epochs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, params, train_ds, test_ds, epochs):\n\u001b[0;32m---> 99\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_ds, batch_size\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_model(params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m], params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m], params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/torch/utils/data/dataloader.py:355\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    351\u001b[0m             sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m batch_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# auto_collation without custom batch_sampler\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     batch_sampler \u001b[38;5;241m=\u001b[39m \u001b[43mBatchSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_last \u001b[38;5;241m=\u001b[39m drop_last\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/torch/utils/data/sampler.py:262\u001b[0m, in \u001b[0;36mBatchSampler.__init__\u001b[0;34m(self, sampler, batch_size, drop_last)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sampler: Union[Sampler[\u001b[38;5;28mint\u001b[39m], Iterable[\u001b[38;5;28mint\u001b[39m]], batch_size: \u001b[38;5;28mint\u001b[39m, drop_last: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# Since collections.abc.Iterable does not check for `__getitem__`, which\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# is one way for an object to be an iterable, we don't do an `isinstance`\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# check here.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    261\u001b[0m             batch_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size should be a positive integer value, but got batch_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(drop_last, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_last should be a boolean value, but got drop_last=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrop_last\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: batch_size should be a positive integer value, but got batch_size=0"
     ]
    }
   ],
   "source": [
    "nnmodel.defaults[\"learning_rate\"] = best[\"learning_rate\"]\n",
    "nnmodel.defaults[\"batch_size\"] = best[\"batch_size\"]\n",
    "dict_param_2 = {\"activation\": [nn.ReLU, nn.Sigmoid, nn.Identity], \"dropout\": [0, 0.2, 0.3, 0.5], \"layer\": test_layer}\n",
    "best, acc = nnmodel.grid_search(dict_param_2, train_small_ds, test_small_ds, epochs=50)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9649b189-f6c2-474e-ae69-727398137a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel.defaults[\"activation\"] = best[\"activation\"]\n",
    "nnmodel.defaults[\"dropout\"] = best[\"dropout\"]\n",
    "nnmodel.defaults[\"layer\"] = best[\"layer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b1c7f-9ab9-43f6-bd54-790ea1b38ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nnmodel.defaults)\n",
    "acc = nnmodel.run(nnmodel.defaults, train_ds, test_ds, 100, out=True, name=\"beer_grid_res\")\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = test(valid_dataloader, nnmodel.model, nnmodel.loss_fn)\n",
    "print(acc)\n",
    "validate(valid_dataloader, nnmodel.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea3ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_best = nnmodel.defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc879c4b",
   "metadata": {},
   "source": [
    "## Local Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7473052a-2f62-4d08-b18c-583738e7c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel = NNModel(layer, device, acc_func=acc_func, loss_func=nn.CrossEntropyLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e14b4-5980-4b83-8c62-01ea1b0ff73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_param = {\"learning_rate\": grid_best[\"learning_rate\"], \"batch_size\": grid_best[\"batch_size\"]}\n",
    "best, acc = nnmodel.local_search(init_param, train_small_ds, test_small_ds, steps=5, epochs=50)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a55130",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel.defaults[\"learning_rate\"] = best[\"learning_rate\"]\n",
    "nnmodel.defaults[\"batch_size\"] = best[\"batch_size\"]\n",
    "init_param = {\"layer\": grid_best[\"layer\"], \"dropout\": grid_best[\"dropout\"]}\n",
    "best, acc = nnmodel.local_search(init_param, train_small_ds, test_small_ds, steps=5, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b57d4-03ca-4cf3-822f-c6b03feaf7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel.defaults[\"dropout\"] = best[\"dropout\"]\n",
    "nnmodel.defaults[\"layer\"] = best[\"layer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb806463-f695-4e3e-b7c5-252bb70be04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nnmodel.defaults)\n",
    "acc = nnmodel.run(nnmodel.defaults, train_ds, test_ds, 100, out=True, name=\"beer_local_res\")\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d8bce-d298-4f7e-b22f-62cd394c76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = test(valid_dataloader, nnmodel.model, nnmodel.loss_fn)\n",
    "print(acc)\n",
    "validate(valid_dataloader, nnmodel.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a80e73",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=20, max_features=100, random_state=42)  \n",
    "\n",
    "rf.fit(X_train_bag, y_train)\n",
    "y_prediction = rf.predict(X_valid_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b19014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_valid, y_prediction)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "f1 = f1_score(y_valid, y_prediction, average='weighted')\n",
    "print(f'F1-Score: {f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
