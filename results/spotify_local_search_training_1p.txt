{'learning_rate': 0.1, 'batch_size': 128, 'layer': [19, 50, 50, 1], 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'dropout': 0}
['learning_rate', 'batch_size']
dict_values([0.1, 128])
run: {'learning_rate': 0.1, 'batch_size': 128, 'layer': [19, 33, 44, 1], 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'dropout': 0}
NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=19, out_features=33, bias=True)
    (1): ReLU()
    (2): Linear(in_features=33, out_features=44, bias=True)
    (3): ReLU()
    (4): Linear(in_features=44, out_features=1, bias=True)
    (5): ReLU()
  )
)
Step 0
Best Params, Parameter Combination [0.1, 128] with keys ['learning_rate', 'batch_size']
 Accuracy: 40.5

run: {'learning_rate': 0.08403, 'batch_size': 93, 'layer': [19, 33, 44, 1], 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'dropout': 0}
NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=19, out_features=33, bias=True)
    (1): ReLU()
    (2): Linear(in_features=33, out_features=44, bias=True)
    (3): ReLU()
    (4): Linear(in_features=44, out_features=1, bias=True)
    (5): ReLU()
  )
)
