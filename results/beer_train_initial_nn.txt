Epoch 1
-------------------------------
loss: 4.648622  [   64/74412]
loss: 4.584782  [ 6464/74412]
loss: 4.272530  [12864/74412]
loss: 4.054912  [19264/74412]
loss: 4.154046  [25664/74412]
loss: 4.005569  [32064/74412]
loss: 4.093634  [38464/74412]
loss: 3.933804  [44864/74412]
loss: 3.970450  [51264/74412]
loss: 3.878860  [57664/74412]
loss: 3.868627  [64064/74412]
loss: 4.026130  [70464/74412]
Test Error: 
 Accuracy: 9.8%, Avg loss: 3.845414 

Epoch 2
-------------------------------
loss: 3.989046  [   64/74412]
loss: 3.925335  [ 6464/74412]
loss: 3.854941  [12864/74412]
loss: 3.647746  [19264/74412]
loss: 3.734114  [25664/74412]
loss: 3.727079  [32064/74412]
loss: 3.748717  [38464/74412]
loss: 3.521474  [44864/74412]
loss: 3.675877  [51264/74412]
loss: 3.555206  [57664/74412]
loss: 3.626075  [64064/74412]
loss: 3.862416  [70464/74412]
Test Error: 
 Accuracy: 13.9%, Avg loss: 3.626276 

Epoch 3
-------------------------------
loss: 3.737796  [   64/74412]
loss: 3.772328  [ 6464/74412]
loss: 3.639985  [12864/74412]
loss: 3.472780  [19264/74412]
loss: 3.628836  [25664/74412]
loss: 3.526870  [32064/74412]
loss: 3.566079  [38464/74412]
loss: 3.389354  [44864/74412]
loss: 3.435603  [51264/74412]
loss: 3.250642  [57664/74412]
loss: 3.392482  [64064/74412]
loss: 3.547019  [70464/74412]
Test Error: 
 Accuracy: 17.6%, Avg loss: 3.459538 

Epoch 4
-------------------------------
loss: 3.620063  [   64/74412]
loss: 3.552089  [ 6464/74412]
loss: 3.427189  [12864/74412]
loss: 3.230156  [19264/74412]
loss: 3.302552  [25664/74412]
loss: 3.508956  [32064/74412]
loss: 3.399121  [38464/74412]
loss: 3.518522  [44864/74412]
loss: 3.288859  [51264/74412]
loss: 3.133137  [57664/74412]
loss: 3.142638  [64064/74412]
loss: 3.292207  [70464/74412]
Test Error: 
 Accuracy: 18.6%, Avg loss: 3.457986 

Epoch 5
-------------------------------
loss: 3.719467  [   64/74412]
loss: 3.154601  [ 6464/74412]
loss: 2.979701  [12864/74412]
loss: 2.788725  [19264/74412]
loss: 3.061455  [25664/74412]
loss: 3.260737  [32064/74412]
loss: 3.321772  [38464/74412]
loss: 3.159647  [44864/74412]
loss: 2.924949  [51264/74412]
loss: 2.574893  [57664/74412]
loss: 2.890908  [64064/74412]
loss: 2.982687  [70464/74412]
Test Error: 
 Accuracy: 23.8%, Avg loss: 3.102624 

Epoch 6
-------------------------------
loss: 3.342023  [   64/74412]
loss: 3.024101  [ 6464/74412]
loss: 2.687924  [12864/74412]
loss: 2.563146  [19264/74412]
loss: 2.820943  [25664/74412]
loss: 2.862884  [32064/74412]
loss: 3.178863  [38464/74412]
loss: 2.899503  [44864/74412]
loss: 2.902503  [51264/74412]
loss: 2.470095  [57664/74412]
loss: 2.748909  [64064/74412]
loss: 2.773541  [70464/74412]
Test Error: 
 Accuracy: 26.7%, Avg loss: 2.911437 

Epoch 7
-------------------------------
loss: 3.134101  [   64/74412]
loss: 2.851228  [ 6464/74412]
loss: 2.528605  [12864/74412]
loss: 2.405394  [19264/74412]
loss: 2.626825  [25664/74412]
loss: 2.735529  [32064/74412]
loss: 3.129690  [38464/74412]
loss: 2.608383  [44864/74412]
loss: 2.693290  [51264/74412]
loss: 2.360525  [57664/74412]
loss: 2.567769  [64064/74412]
loss: 2.611301  [70464/74412]
Test Error: 
 Accuracy: 28.9%, Avg loss: 2.766518 

Epoch 8
-------------------------------
loss: 2.980320  [   64/74412]
loss: 2.711472  [ 6464/74412]
loss: 2.405511  [12864/74412]
loss: 2.257370  [19264/74412]
loss: 2.460801  [25664/74412]
loss: 2.752032  [32064/74412]
loss: 3.050099  [38464/74412]
loss: 2.415230  [44864/74412]
loss: 2.512085  [51264/74412]
loss: 2.248063  [57664/74412]
loss: 2.391871  [64064/74412]
loss: 2.450893  [70464/74412]
Test Error: 
 Accuracy: 32.5%, Avg loss: 2.615226 

Epoch 9
-------------------------------
loss: 2.845895  [   64/74412]
loss: 2.583338  [ 6464/74412]
loss: 2.262055  [12864/74412]
loss: 2.094979  [19264/74412]
loss: 2.257667  [25664/74412]
loss: 2.581073  [32064/74412]
loss: 2.887715  [38464/74412]
loss: 2.451920  [44864/74412]
loss: 2.374180  [51264/74412]
loss: 2.133205  [57664/74412]
loss: 2.258734  [64064/74412]
loss: 2.281286  [70464/74412]
Test Error: 
 Accuracy: 35.3%, Avg loss: 2.530860 

Epoch 10
-------------------------------
loss: 2.802517  [   64/74412]
loss: 2.500171  [ 6464/74412]
loss: 2.108342  [12864/74412]
loss: 1.962722  [19264/74412]
loss: 2.109316  [25664/74412]
loss: 2.477443  [32064/74412]
loss: 2.726897  [38464/74412]
loss: 2.419353  [44864/74412]
loss: 2.245556  [51264/74412]
loss: 1.998705  [57664/74412]
loss: 2.225308  [64064/74412]
loss: 2.096945  [70464/74412]
Test Error: 
 Accuracy: 39.3%, Avg loss: 2.345354 

Epoch 11
-------------------------------
loss: 2.671845  [   64/74412]
loss: 2.352211  [ 6464/74412]
loss: 1.998964  [12864/74412]
loss: 1.926155  [19264/74412]
loss: 2.019202  [25664/74412]
loss: 2.365898  [32064/74412]
loss: 2.588436  [38464/74412]
loss: 2.273369  [44864/74412]
loss: 2.170316  [51264/74412]
loss: 1.898492  [57664/74412]
loss: 2.128500  [64064/74412]
loss: 1.926512  [70464/74412]
Test Error: 
 Accuracy: 42.2%, Avg loss: 2.226478 

Epoch 12
-------------------------------
loss: 2.588883  [   64/74412]
loss: 2.230163  [ 6464/74412]
loss: 1.938756  [12864/74412]
loss: 1.862710  [19264/74412]
loss: 1.901969  [25664/74412]
loss: 2.287894  [32064/74412]
loss: 2.488816  [38464/74412]
loss: 2.122319  [44864/74412]
loss: 2.078618  [51264/74412]
loss: 1.801952  [57664/74412]
loss: 2.093343  [64064/74412]
loss: 1.814067  [70464/74412]
Test Error: 
 Accuracy: 42.5%, Avg loss: 2.212885 

Epoch 13
-------------------------------
loss: 2.604303  [   64/74412]
loss: 2.157366  [ 6464/74412]
loss: 1.854317  [12864/74412]
loss: 1.832127  [19264/74412]
loss: 1.806235  [25664/74412]
loss: 2.216946  [32064/74412]
loss: 2.379329  [38464/74412]
loss: 1.972670  [44864/74412]
loss: 1.960808  [51264/74412]
loss: 1.710981  [57664/74412]
loss: 2.014709  [64064/74412]
loss: 1.702445  [70464/74412]
Test Error: 
 Accuracy: 43.0%, Avg loss: 2.197329 

Epoch 14
-------------------------------
loss: 2.617538  [   64/74412]
loss: 2.102209  [ 6464/74412]
loss: 1.789025  [12864/74412]
loss: 1.761947  [19264/74412]
loss: 1.745981  [25664/74412]
loss: 2.177947  [32064/74412]
loss: 2.267933  [38464/74412]
loss: 1.822600  [44864/74412]
loss: 1.897593  [51264/74412]
loss: 1.670479  [57664/74412]
loss: 2.010453  [64064/74412]
loss: 1.621726  [70464/74412]
Test Error: 
 Accuracy: 43.6%, Avg loss: 2.180645 

Epoch 15
-------------------------------
loss: 2.626119  [   64/74412]
loss: 1.981618  [ 6464/74412]
loss: 1.711271  [12864/74412]
loss: 1.723901  [19264/74412]
loss: 1.684478  [25664/74412]
loss: 2.136820  [32064/74412]
loss: 2.172303  [38464/74412]
loss: 1.733441  [44864/74412]
loss: 1.774720  [51264/74412]
loss: 1.606164  [57664/74412]
loss: 2.020478  [64064/74412]
loss: 1.564806  [70464/74412]
Test Error: 
 Accuracy: 46.1%, Avg loss: 2.088721 

Epoch 16
-------------------------------
loss: 2.554476  [   64/74412]
loss: 1.901104  [ 6464/74412]
loss: 1.656109  [12864/74412]
loss: 1.641658  [19264/74412]
loss: 1.625594  [25664/74412]
loss: 2.083697  [32064/74412]
loss: 2.074670  [38464/74412]
loss: 1.641353  [44864/74412]
loss: 1.685409  [51264/74412]
loss: 1.537027  [57664/74412]
loss: 1.954597  [64064/74412]
loss: 1.525240  [70464/74412]
Test Error: 
 Accuracy: 47.5%, Avg loss: 2.038360 

Epoch 17
-------------------------------
loss: 2.500857  [   64/74412]
loss: 1.821887  [ 6464/74412]
loss: 1.611609  [12864/74412]
loss: 1.585726  [19264/74412]
loss: 1.583091  [25664/74412]
loss: 2.037622  [32064/74412]
loss: 2.036385  [38464/74412]
loss: 1.588891  [44864/74412]
loss: 1.605114  [51264/74412]
loss: 1.494619  [57664/74412]
loss: 1.896950  [64064/74412]
loss: 1.484646  [70464/74412]
Test Error: 
 Accuracy: 49.7%, Avg loss: 1.957122 

Epoch 18
-------------------------------
loss: 2.431642  [   64/74412]
loss: 1.778218  [ 6464/74412]
loss: 1.600939  [12864/74412]
loss: 1.529184  [19264/74412]
loss: 1.563994  [25664/74412]
loss: 2.009514  [32064/74412]
loss: 2.038959  [38464/74412]
loss: 1.549989  [44864/74412]
loss: 1.547206  [51264/74412]
loss: 1.457775  [57664/74412]
loss: 1.871356  [64064/74412]
loss: 1.453630  [70464/74412]
Test Error: 
 Accuracy: 51.4%, Avg loss: 1.882476 

Epoch 19
-------------------------------
loss: 2.355682  [   64/74412]
loss: 1.718519  [ 6464/74412]
loss: 1.580957  [12864/74412]
loss: 1.489781  [19264/74412]
loss: 1.553085  [25664/74412]
loss: 2.009820  [32064/74412]
loss: 2.025142  [38464/74412]
loss: 1.513569  [44864/74412]
loss: 1.495723  [51264/74412]
loss: 1.425176  [57664/74412]
loss: 1.840581  [64064/74412]
loss: 1.425910  [70464/74412]
Test Error: 
 Accuracy: 52.9%, Avg loss: 1.801836 

Epoch 20
-------------------------------
loss: 2.279804  [   64/74412]
loss: 1.648452  [ 6464/74412]
loss: 1.552823  [12864/74412]
loss: 1.459317  [19264/74412]
loss: 1.552645  [25664/74412]
loss: 1.987075  [32064/74412]
loss: 2.081934  [38464/74412]
loss: 1.448494  [44864/74412]
loss: 1.447433  [51264/74412]
loss: 1.398187  [57664/74412]
loss: 1.841853  [64064/74412]
loss: 1.402357  [70464/74412]
Test Error: 
 Accuracy: 54.6%, Avg loss: 1.739550 

Epoch 21
-------------------------------
loss: 2.219550  [   64/74412]
loss: 1.616243  [ 6464/74412]
loss: 1.523934  [12864/74412]
loss: 1.422487  [19264/74412]
loss: 1.539238  [25664/74412]
loss: 1.982933  [32064/74412]
loss: 2.085901  [38464/74412]
loss: 1.414304  [44864/74412]
loss: 1.398112  [51264/74412]
loss: 1.374497  [57664/74412]
loss: 1.841901  [64064/74412]
loss: 1.375994  [70464/74412]
Test Error: 
 Accuracy: 56.7%, Avg loss: 1.659340 

Epoch 22
-------------------------------
loss: 2.131864  [   64/74412]
loss: 1.581635  [ 6464/74412]
loss: 1.510565  [12864/74412]
loss: 1.394639  [19264/74412]
loss: 1.507997  [25664/74412]
loss: 1.945554  [32064/74412]
loss: 1.989903  [38464/74412]
loss: 1.389151  [44864/74412]
loss: 1.362368  [51264/74412]
loss: 1.346525  [57664/74412]
loss: 1.825585  [64064/74412]
loss: 1.366592  [70464/74412]
Test Error: 
 Accuracy: 59.1%, Avg loss: 1.577474 

Epoch 23
-------------------------------
loss: 2.046239  [   64/74412]
loss: 1.538299  [ 6464/74412]
loss: 1.458128  [12864/74412]
loss: 1.359485  [19264/74412]
loss: 1.482101  [25664/74412]
loss: 1.933311  [32064/74412]
loss: 1.908001  [38464/74412]
loss: 1.360714  [44864/74412]
loss: 1.331543  [51264/74412]
loss: 1.334921  [57664/74412]
loss: 1.813643  [64064/74412]
loss: 1.341676  [70464/74412]
Test Error: 
 Accuracy: 59.4%, Avg loss: 1.563671 

Epoch 24
-------------------------------
loss: 2.007178  [   64/74412]
loss: 1.499943  [ 6464/74412]
loss: 1.429871  [12864/74412]
loss: 1.316765  [19264/74412]
loss: 1.451041  [25664/74412]
loss: 1.904818  [32064/74412]
loss: 1.971783  [38464/74412]
loss: 1.312330  [44864/74412]
loss: 1.296606  [51264/74412]
loss: 1.332117  [57664/74412]
loss: 1.756184  [64064/74412]
loss: 1.320112  [70464/74412]
Test Error: 
 Accuracy: 60.7%, Avg loss: 1.519526 

Epoch 25
-------------------------------
loss: 1.948296  [   64/74412]
loss: 1.457731  [ 6464/74412]
loss: 1.416585  [12864/74412]
loss: 1.291421  [19264/74412]
loss: 1.446928  [25664/74412]
loss: 1.865726  [32064/74412]
loss: 1.906324  [38464/74412]
loss: 1.285918  [44864/74412]
loss: 1.274858  [51264/74412]
loss: 1.304667  [57664/74412]
loss: 1.738949  [64064/74412]
loss: 1.293312  [70464/74412]
Test Error: 
 Accuracy: 61.5%, Avg loss: 1.498128 

Epoch 26
-------------------------------
loss: 1.915818  [   64/74412]
loss: 1.409826  [ 6464/74412]
loss: 1.395146  [12864/74412]
loss: 1.270055  [19264/74412]
loss: 1.444975  [25664/74412]
loss: 1.822210  [32064/74412]
loss: 1.793722  [38464/74412]
loss: 1.269652  [44864/74412]
loss: 1.250465  [51264/74412]
loss: 1.286860  [57664/74412]
loss: 1.710005  [64064/74412]
loss: 1.255455  [70464/74412]
Test Error: 
 Accuracy: 60.8%, Avg loss: 1.514511 

Epoch 27
-------------------------------
loss: 1.935046  [   64/74412]
loss: 1.401073  [ 6464/74412]
loss: 1.379792  [12864/74412]
loss: 1.240414  [19264/74412]
loss: 1.408175  [25664/74412]
loss: 1.816716  [32064/74412]
loss: 1.747242  [38464/74412]
loss: 1.223503  [44864/74412]
loss: 1.237058  [51264/74412]
loss: 1.277895  [57664/74412]
loss: 1.657283  [64064/74412]
loss: 1.242433  [70464/74412]
Test Error: 
 Accuracy: 62.3%, Avg loss: 1.478757 

Epoch 28
-------------------------------
loss: 1.876695  [   64/74412]
loss: 1.334568  [ 6464/74412]
loss: 1.372372  [12864/74412]
loss: 1.220415  [19264/74412]
loss: 1.379319  [25664/74412]
loss: 1.823679  [32064/74412]
loss: 1.783358  [38464/74412]
loss: 1.205833  [44864/74412]
loss: 1.209544  [51264/74412]
loss: 1.264088  [57664/74412]
loss: 1.630584  [64064/74412]
loss: 1.205411  [70464/74412]
Test Error: 
 Accuracy: 62.9%, Avg loss: 1.462296 

Epoch 29
-------------------------------
loss: 1.857531  [   64/74412]
loss: 1.318217  [ 6464/74412]
loss: 1.352532  [12864/74412]
loss: 1.203604  [19264/74412]
loss: 1.352482  [25664/74412]
loss: 1.790493  [32064/74412]
loss: 1.682326  [38464/74412]
loss: 1.159864  [44864/74412]
loss: 1.189700  [51264/74412]
loss: 1.239591  [57664/74412]
loss: 1.600167  [64064/74412]
loss: 1.182957  [70464/74412]
Test Error: 
 Accuracy: 63.6%, Avg loss: 1.420490 

Epoch 30
-------------------------------
loss: 1.831492  [   64/74412]
loss: 1.286147  [ 6464/74412]
loss: 1.326297  [12864/74412]
loss: 1.205388  [19264/74412]
loss: 1.309700  [25664/74412]
loss: 1.761745  [32064/74412]
loss: 1.685759  [38464/74412]
loss: 1.130420  [44864/74412]
loss: 1.166522  [51264/74412]
loss: 1.225081  [57664/74412]
loss: 1.562733  [64064/74412]
loss: 1.162282  [70464/74412]
Test Error: 
 Accuracy: 63.8%, Avg loss: 1.412489 

Epoch 31
-------------------------------
loss: 1.803473  [   64/74412]
loss: 1.255065  [ 6464/74412]
loss: 1.330053  [12864/74412]
loss: 1.184179  [19264/74412]
loss: 1.314973  [25664/74412]
loss: 1.752083  [32064/74412]
loss: 1.720843  [38464/74412]
loss: 1.101739  [44864/74412]
loss: 1.148625  [51264/74412]
loss: 1.226442  [57664/74412]
loss: 1.536723  [64064/74412]
loss: 1.145084  [70464/74412]
Test Error: 
 Accuracy: 64.4%, Avg loss: 1.388706 

Epoch 32
-------------------------------
loss: 1.760675  [   64/74412]
loss: 1.232612  [ 6464/74412]
loss: 1.321666  [12864/74412]
loss: 1.166928  [19264/74412]
loss: 1.264034  [25664/74412]
loss: 1.736416  [32064/74412]
loss: 1.752479  [38464/74412]
loss: 1.076879  [44864/74412]
loss: 1.125687  [51264/74412]
loss: 1.198280  [57664/74412]
loss: 1.501793  [64064/74412]
loss: 1.123736  [70464/74412]
Test Error: 
 Accuracy: 64.2%, Avg loss: 1.399002 

Epoch 33
-------------------------------
loss: 1.787107  [   64/74412]
loss: 1.225463  [ 6464/74412]
loss: 1.319899  [12864/74412]
loss: 1.152856  [19264/74412]
loss: 1.245449  [25664/74412]
loss: 1.692331  [32064/74412]
loss: 1.747295  [38464/74412]
loss: 1.053618  [44864/74412]
loss: 1.110201  [51264/74412]
loss: 1.230168  [57664/74412]
loss: 1.491548  [64064/74412]
loss: 1.108481  [70464/74412]
Test Error: 
 Accuracy: 64.7%, Avg loss: 1.379139 

Epoch 34
-------------------------------
loss: 1.749854  [   64/74412]
loss: 1.195614  [ 6464/74412]
loss: 1.306710  [12864/74412]
loss: 1.146647  [19264/74412]
loss: 1.261405  [25664/74412]
loss: 1.685753  [32064/74412]
loss: 1.668793  [38464/74412]
loss: 1.038108  [44864/74412]
loss: 1.094676  [51264/74412]
loss: 1.211914  [57664/74412]
loss: 1.473540  [64064/74412]
loss: 1.094736  [70464/74412]
Test Error: 
 Accuracy: 65.5%, Avg loss: 1.343728 

Epoch 35
-------------------------------
loss: 1.696463  [   64/74412]
loss: 1.203871  [ 6464/74412]
loss: 1.343231  [12864/74412]
loss: 1.126042  [19264/74412]
loss: 1.246562  [25664/74412]
loss: 1.655091  [32064/74412]
loss: 1.726834  [38464/74412]
loss: 1.013649  [44864/74412]
loss: 1.078779  [51264/74412]
loss: 1.179811  [57664/74412]
loss: 1.464016  [64064/74412]
loss: 1.082881  [70464/74412]
Test Error: 
 Accuracy: 65.1%, Avg loss: 1.361150 

Epoch 36
-------------------------------
loss: 1.701547  [   64/74412]
loss: 1.188728  [ 6464/74412]
loss: 1.322838  [12864/74412]
loss: 1.105986  [19264/74412]
loss: 1.230741  [25664/74412]
loss: 1.639814  [32064/74412]
loss: 1.761106  [38464/74412]
loss: 0.995991  [44864/74412]
loss: 1.065829  [51264/74412]
loss: 1.180441  [57664/74412]
loss: 1.431957  [64064/74412]
loss: 1.052655  [70464/74412]
Test Error: 
 Accuracy: 65.8%, Avg loss: 1.338249 

Epoch 37
-------------------------------
loss: 1.674491  [   64/74412]
loss: 1.156078  [ 6464/74412]
loss: 1.280542  [12864/74412]
loss: 1.100872  [19264/74412]
loss: 1.206976  [25664/74412]
loss: 1.618947  [32064/74412]
loss: 1.671306  [38464/74412]
loss: 0.984800  [44864/74412]
loss: 1.045416  [51264/74412]
loss: 1.147099  [57664/74412]
loss: 1.415531  [64064/74412]
loss: 1.028681  [70464/74412]
Test Error: 
 Accuracy: 65.6%, Avg loss: 1.346911 

Epoch 38
-------------------------------
loss: 1.676106  [   64/74412]
loss: 1.169385  [ 6464/74412]
loss: 1.307638  [12864/74412]
loss: 1.085444  [19264/74412]
loss: 1.195968  [25664/74412]
loss: 1.596973  [32064/74412]
loss: 1.687049  [38464/74412]
loss: 0.970837  [44864/74412]
loss: 1.036060  [51264/74412]
loss: 1.150645  [57664/74412]
loss: 1.377294  [64064/74412]
loss: 1.004765  [70464/74412]
Test Error: 
 Accuracy: 66.6%, Avg loss: 1.305738 

Epoch 39
-------------------------------
loss: 1.640135  [   64/74412]
loss: 1.118960  [ 6464/74412]
loss: 1.305268  [12864/74412]
loss: 1.050516  [19264/74412]
loss: 1.151373  [25664/74412]
loss: 1.584180  [32064/74412]
loss: 1.659306  [38464/74412]
loss: 0.956154  [44864/74412]
loss: 1.011642  [51264/74412]
loss: 1.155320  [57664/74412]
loss: 1.377707  [64064/74412]
loss: 0.990712  [70464/74412]
Test Error: 
 Accuracy: 67.1%, Avg loss: 1.293181 

Epoch 40
-------------------------------
loss: 1.618755  [   64/74412]
loss: 1.123044  [ 6464/74412]
loss: 1.282939  [12864/74412]
loss: 1.041391  [19264/74412]
loss: 1.148247  [25664/74412]
loss: 1.549851  [32064/74412]
loss: 1.604672  [38464/74412]
loss: 0.941613  [44864/74412]
loss: 1.009198  [51264/74412]
loss: 1.145781  [57664/74412]
loss: 1.353348  [64064/74412]
loss: 0.985387  [70464/74412]
Test Error: 
 Accuracy: 67.2%, Avg loss: 1.278394 

Epoch 41
-------------------------------
loss: 1.610527  [   64/74412]
loss: 1.090370  [ 6464/74412]
loss: 1.273434  [12864/74412]
loss: 1.020300  [19264/74412]
loss: 1.140216  [25664/74412]
loss: 1.545739  [32064/74412]
loss: 1.559402  [38464/74412]
loss: 0.926605  [44864/74412]
loss: 0.993112  [51264/74412]
loss: 1.086071  [57664/74412]
loss: 1.314575  [64064/74412]
loss: 0.966236  [70464/74412]
Test Error: 
 Accuracy: 67.4%, Avg loss: 1.281488 

Epoch 42
-------------------------------
loss: 1.592634  [   64/74412]
loss: 1.100576  [ 6464/74412]
loss: 1.253383  [12864/74412]
loss: 1.026008  [19264/74412]
loss: 1.135044  [25664/74412]
loss: 1.518726  [32064/74412]
loss: 1.541599  [38464/74412]
loss: 0.912474  [44864/74412]
loss: 0.984434  [51264/74412]
loss: 1.099392  [57664/74412]
loss: 1.302422  [64064/74412]
loss: 0.938628  [70464/74412]
Test Error: 
 Accuracy: 67.1%, Avg loss: 1.282457 

Epoch 43
-------------------------------
loss: 1.598796  [   64/74412]
loss: 1.080844  [ 6464/74412]
loss: 1.229090  [12864/74412]
loss: 1.011407  [19264/74412]
loss: 1.095574  [25664/74412]
loss: 1.488190  [32064/74412]
loss: 1.479723  [38464/74412]
loss: 0.923606  [44864/74412]
loss: 0.989316  [51264/74412]
loss: 1.113378  [57664/74412]
loss: 1.278586  [64064/74412]
loss: 0.936222  [70464/74412]
Test Error: 
 Accuracy: 67.6%, Avg loss: 1.263946 

Epoch 44
-------------------------------
loss: 1.570123  [   64/74412]
loss: 1.077283  [ 6464/74412]
loss: 1.234564  [12864/74412]
loss: 0.994280  [19264/74412]
loss: 1.085529  [25664/74412]
loss: 1.512362  [32064/74412]
loss: 1.424652  [38464/74412]
loss: 0.895540  [44864/74412]
loss: 0.952620  [51264/74412]
loss: 1.061137  [57664/74412]
loss: 1.278081  [64064/74412]
loss: 0.928523  [70464/74412]
Test Error: 
 Accuracy: 67.2%, Avg loss: 1.274207 

Epoch 45
-------------------------------
loss: 1.592308  [   64/74412]
loss: 1.076464  [ 6464/74412]
loss: 1.199915  [12864/74412]
loss: 0.988643  [19264/74412]
loss: 1.080217  [25664/74412]
loss: 1.488213  [32064/74412]
loss: 1.500694  [38464/74412]
loss: 0.888447  [44864/74412]
loss: 0.960760  [51264/74412]
loss: 1.070204  [57664/74412]
loss: 1.247343  [64064/74412]
loss: 0.916466  [70464/74412]
Test Error: 
 Accuracy: 68.0%, Avg loss: 1.243781 

Epoch 46
-------------------------------
loss: 1.555895  [   64/74412]
loss: 1.062705  [ 6464/74412]
loss: 1.220988  [12864/74412]
loss: 0.969319  [19264/74412]
loss: 1.070018  [25664/74412]
loss: 1.470904  [32064/74412]
loss: 1.454714  [38464/74412]
loss: 0.878986  [44864/74412]
loss: 0.957548  [51264/74412]
loss: 1.047722  [57664/74412]
loss: 1.220350  [64064/74412]
loss: 0.900720  [70464/74412]
Test Error: 
 Accuracy: 68.4%, Avg loss: 1.226365 

Epoch 47
-------------------------------
loss: 1.526337  [   64/74412]
loss: 1.055300  [ 6464/74412]
loss: 1.169313  [12864/74412]
loss: 0.950081  [19264/74412]
loss: 1.058302  [25664/74412]
loss: 1.454999  [32064/74412]
loss: 1.383643  [38464/74412]
loss: 0.867655  [44864/74412]
loss: 0.930903  [51264/74412]
loss: 1.035866  [57664/74412]
loss: 1.202192  [64064/74412]
loss: 0.886712  [70464/74412]
Test Error: 
 Accuracy: 69.1%, Avg loss: 1.207114 

Epoch 48
-------------------------------
loss: 1.507110  [   64/74412]
loss: 1.046959  [ 6464/74412]
loss: 1.118567  [12864/74412]
loss: 0.953498  [19264/74412]
loss: 1.058298  [25664/74412]
loss: 1.442440  [32064/74412]
loss: 1.368255  [38464/74412]
loss: 0.858684  [44864/74412]
loss: 0.924532  [51264/74412]
loss: 1.004164  [57664/74412]
loss: 1.183094  [64064/74412]
loss: 0.892265  [70464/74412]
Test Error: 
 Accuracy: 69.0%, Avg loss: 1.208323 

Epoch 49
-------------------------------
loss: 1.513678  [   64/74412]
loss: 1.045593  [ 6464/74412]
loss: 1.114191  [12864/74412]
loss: 0.931226  [19264/74412]
loss: 1.053411  [25664/74412]
loss: 1.421626  [32064/74412]
loss: 1.400805  [38464/74412]
loss: 0.847817  [44864/74412]
loss: 0.915814  [51264/74412]
loss: 0.971400  [57664/74412]
loss: 1.172031  [64064/74412]
loss: 0.886891  [70464/74412]
Test Error: 
 Accuracy: 69.5%, Avg loss: 1.185610 

Epoch 50
-------------------------------
loss: 1.494954  [   64/74412]
loss: 1.047088  [ 6464/74412]
loss: 1.113760  [12864/74412]
loss: 0.932775  [19264/74412]
loss: 1.032793  [25664/74412]
loss: 1.385879  [32064/74412]
loss: 1.320713  [38464/74412]
loss: 0.835719  [44864/74412]
loss: 0.920172  [51264/74412]
loss: 1.004024  [57664/74412]
loss: 1.131925  [64064/74412]
loss: 0.863441  [70464/74412]
Test Error: 
 Accuracy: 68.7%, Avg loss: 1.215034 

Epoch 51
-------------------------------
loss: 1.512274  [   64/74412]
loss: 1.015862  [ 6464/74412]
loss: 1.067306  [12864/74412]
loss: 0.918991  [19264/74412]
loss: 1.020746  [25664/74412]
loss: 1.405915  [32064/74412]
loss: 1.331333  [38464/74412]
loss: 0.829413  [44864/74412]
loss: 0.898896  [51264/74412]
loss: 0.963260  [57664/74412]
loss: 1.121992  [64064/74412]
loss: 0.837196  [70464/74412]
Test Error: 
 Accuracy: 69.9%, Avg loss: 1.164930 

Epoch 52
-------------------------------
loss: 1.465664  [   64/74412]
loss: 1.023510  [ 6464/74412]
loss: 1.083066  [12864/74412]
loss: 0.923429  [19264/74412]
loss: 1.019428  [25664/74412]
loss: 1.379027  [32064/74412]
loss: 1.304284  [38464/74412]
loss: 0.827728  [44864/74412]
loss: 0.910860  [51264/74412]
loss: 0.992251  [57664/74412]
loss: 1.100239  [64064/74412]
loss: 0.843030  [70464/74412]
Test Error: 
 Accuracy: 68.9%, Avg loss: 1.196404 

Epoch 53
-------------------------------
loss: 1.483087  [   64/74412]
loss: 1.016255  [ 6464/74412]
loss: 1.097341  [12864/74412]
loss: 0.912299  [19264/74412]
loss: 0.996166  [25664/74412]
loss: 1.358033  [32064/74412]
loss: 1.260557  [38464/74412]
loss: 0.810977  [44864/74412]
loss: 0.903269  [51264/74412]
loss: 0.942276  [57664/74412]
loss: 1.086061  [64064/74412]
loss: 0.840979  [70464/74412]
Test Error: 
 Accuracy: 69.2%, Avg loss: 1.187623 

Epoch 54
-------------------------------
loss: 1.467657  [   64/74412]
loss: 1.010233  [ 6464/74412]
loss: 1.021391  [12864/74412]
loss: 0.912027  [19264/74412]
loss: 0.985013  [25664/74412]
loss: 1.365446  [32064/74412]
loss: 1.253703  [38464/74412]
loss: 0.794520  [44864/74412]
loss: 0.892709  [51264/74412]
loss: 0.953774  [57664/74412]
loss: 1.056667  [64064/74412]
loss: 0.815749  [70464/74412]
Test Error: 
 Accuracy: 70.9%, Avg loss: 1.129047 

Epoch 55
-------------------------------
loss: 1.416614  [   64/74412]
loss: 1.005244  [ 6464/74412]
loss: 1.037618  [12864/74412]
loss: 0.879056  [19264/74412]
loss: 0.982866  [25664/74412]
loss: 1.350857  [32064/74412]
loss: 1.228066  [38464/74412]
loss: 0.790290  [44864/74412]
loss: 0.896325  [51264/74412]
loss: 0.950855  [57664/74412]
loss: 1.034912  [64064/74412]
loss: 0.800728  [70464/74412]
Test Error: 
 Accuracy: 70.0%, Avg loss: 1.153867 

Epoch 56
-------------------------------
loss: 1.434761  [   64/74412]
loss: 0.982117  [ 6464/74412]
loss: 1.030410  [12864/74412]
loss: 0.879999  [19264/74412]
loss: 0.954752  [25664/74412]
loss: 1.337445  [32064/74412]
loss: 1.235688  [38464/74412]
loss: 0.773198  [44864/74412]
loss: 0.888372  [51264/74412]
loss: 0.897431  [57664/74412]
loss: 1.023193  [64064/74412]
loss: 0.782564  [70464/74412]
Test Error: 
 Accuracy: 71.2%, Avg loss: 1.118169 

Epoch 57
-------------------------------
loss: 1.400430  [   64/74412]
loss: 1.000697  [ 6464/74412]
loss: 1.031113  [12864/74412]
loss: 0.875319  [19264/74412]
loss: 0.962449  [25664/74412]
loss: 1.305044  [32064/74412]
loss: 1.198832  [38464/74412]
loss: 0.768485  [44864/74412]
loss: 0.897600  [51264/74412]
loss: 0.893369  [57664/74412]
loss: 1.006456  [64064/74412]
loss: 0.785096  [70464/74412]
Test Error: 
 Accuracy: 71.6%, Avg loss: 1.110530 

Epoch 58
-------------------------------
loss: 1.375745  [   64/74412]
loss: 0.975184  [ 6464/74412]
loss: 0.999963  [12864/74412]
loss: 0.860652  [19264/74412]
loss: 0.944340  [25664/74412]
loss: 1.315308  [32064/74412]
loss: 1.248444  [38464/74412]
loss: 0.746764  [44864/74412]
loss: 0.885687  [51264/74412]
loss: 0.873693  [57664/74412]
loss: 0.979250  [64064/74412]
loss: 0.758019  [70464/74412]
Test Error: 
 Accuracy: 71.2%, Avg loss: 1.120969 

Epoch 59
-------------------------------
loss: 1.380596  [   64/74412]
loss: 0.977288  [ 6464/74412]
loss: 1.005334  [12864/74412]
loss: 0.871171  [19264/74412]
loss: 0.943618  [25664/74412]
loss: 1.301424  [32064/74412]
loss: 1.165988  [38464/74412]
loss: 0.750819  [44864/74412]
loss: 0.897910  [51264/74412]
loss: 0.852820  [57664/74412]
loss: 0.979835  [64064/74412]
loss: 0.771593  [70464/74412]
Test Error: 
 Accuracy: 71.2%, Avg loss: 1.119709 

Epoch 60
-------------------------------
loss: 1.364230  [   64/74412]
loss: 0.954612  [ 6464/74412]
loss: 0.974682  [12864/74412]
loss: 0.857924  [19264/74412]
loss: 0.922734  [25664/74412]
loss: 1.287803  [32064/74412]
loss: 1.142883  [38464/74412]
loss: 0.750728  [44864/74412]
loss: 0.865227  [51264/74412]
loss: 0.855450  [57664/74412]
loss: 0.986284  [64064/74412]
loss: 0.753382  [70464/74412]
Test Error: 
 Accuracy: 71.5%, Avg loss: 1.110104 

Epoch 61
-------------------------------
loss: 1.361714  [   64/74412]
loss: 0.943575  [ 6464/74412]
loss: 0.996020  [12864/74412]
loss: 0.849965  [19264/74412]
loss: 0.939817  [25664/74412]
loss: 1.284036  [32064/74412]
loss: 1.141808  [38464/74412]
loss: 0.761043  [44864/74412]
loss: 0.871266  [51264/74412]
loss: 0.857218  [57664/74412]
loss: 0.967487  [64064/74412]
loss: 0.754644  [70464/74412]
Test Error: 
 Accuracy: 71.8%, Avg loss: 1.088264 

Epoch 62
-------------------------------
loss: 1.343035  [   64/74412]
loss: 0.975549  [ 6464/74412]
loss: 0.972315  [12864/74412]
loss: 0.859749  [19264/74412]
loss: 0.941994  [25664/74412]
loss: 1.263722  [32064/74412]
loss: 1.142221  [38464/74412]
loss: 0.742045  [44864/74412]
loss: 0.877217  [51264/74412]
loss: 0.802865  [57664/74412]
loss: 0.957740  [64064/74412]
loss: 0.741085  [70464/74412]
Test Error: 
 Accuracy: 72.0%, Avg loss: 1.095171 

Epoch 63
-------------------------------
loss: 1.326901  [   64/74412]
loss: 0.955658  [ 6464/74412]
loss: 0.991332  [12864/74412]
loss: 0.830882  [19264/74412]
loss: 0.941406  [25664/74412]
loss: 1.261684  [32064/74412]
loss: 1.159513  [38464/74412]
loss: 0.743197  [44864/74412]
loss: 0.870543  [51264/74412]
loss: 0.803089  [57664/74412]
loss: 0.922280  [64064/74412]
loss: 0.745396  [70464/74412]
Test Error: 
 Accuracy: 72.0%, Avg loss: 1.089374 

Epoch 64
-------------------------------
loss: 1.333202  [   64/74412]
loss: 0.951131  [ 6464/74412]
loss: 0.994331  [12864/74412]
loss: 0.830202  [19264/74412]
loss: 0.903545  [25664/74412]
loss: 1.242124  [32064/74412]
loss: 1.101101  [38464/74412]
loss: 0.727506  [44864/74412]
loss: 0.886674  [51264/74412]
loss: 0.804617  [57664/74412]
loss: 0.914384  [64064/74412]
loss: 0.728285  [70464/74412]
Test Error: 
 Accuracy: 72.0%, Avg loss: 1.087942 

Epoch 65
-------------------------------
loss: 1.336936  [   64/74412]
loss: 0.947441  [ 6464/74412]
loss: 0.973595  [12864/74412]
loss: 0.819687  [19264/74412]
loss: 0.909716  [25664/74412]
loss: 1.204178  [32064/74412]
loss: 1.135541  [38464/74412]
loss: 0.719691  [44864/74412]
loss: 0.873810  [51264/74412]
loss: 0.800469  [57664/74412]
loss: 0.886606  [64064/74412]
loss: 0.720129  [70464/74412]
Test Error: 
 Accuracy: 71.9%, Avg loss: 1.083879 

Epoch 66
-------------------------------
loss: 1.339817  [   64/74412]
loss: 0.941456  [ 6464/74412]
loss: 0.955999  [12864/74412]
loss: 0.826289  [19264/74412]
loss: 0.926102  [25664/74412]
loss: 1.212778  [32064/74412]
loss: 1.095191  [38464/74412]
loss: 0.726336  [44864/74412]
loss: 0.877521  [51264/74412]
loss: 0.807003  [57664/74412]
loss: 0.901190  [64064/74412]
loss: 0.711302  [70464/74412]
Test Error: 
 Accuracy: 71.8%, Avg loss: 1.092807 

Epoch 67
-------------------------------
loss: 1.332155  [   64/74412]
loss: 0.948704  [ 6464/74412]
loss: 0.955371  [12864/74412]
loss: 0.807396  [19264/74412]
loss: 0.914981  [25664/74412]
loss: 1.249632  [32064/74412]
loss: 1.100515  [38464/74412]
loss: 0.725851  [44864/74412]
loss: 0.870332  [51264/74412]
loss: 0.769131  [57664/74412]
loss: 0.869304  [64064/74412]
loss: 0.704719  [70464/74412]
Test Error: 
 Accuracy: 72.2%, Avg loss: 1.077203 

Epoch 68
-------------------------------
loss: 1.312256  [   64/74412]
loss: 0.944560  [ 6464/74412]
loss: 0.957157  [12864/74412]
loss: 0.794553  [19264/74412]
loss: 0.910267  [25664/74412]
loss: 1.245632  [32064/74412]
loss: 1.134108  [38464/74412]
loss: 0.712635  [44864/74412]
loss: 0.854473  [51264/74412]
loss: 0.749941  [57664/74412]
loss: 0.858253  [64064/74412]
loss: 0.687864  [70464/74412]
Test Error: 
 Accuracy: 72.0%, Avg loss: 1.080136 

Epoch 69
-------------------------------
loss: 1.330124  [   64/74412]
loss: 0.938311  [ 6464/74412]
loss: 0.930348  [12864/74412]
loss: 0.794152  [19264/74412]
loss: 0.938318  [25664/74412]
loss: 1.231054  [32064/74412]
loss: 1.134725  [38464/74412]
loss: 0.694371  [44864/74412]
loss: 0.848330  [51264/74412]
loss: 0.760100  [57664/74412]
loss: 0.850674  [64064/74412]
loss: 0.700236  [70464/74412]
Test Error: 
 Accuracy: 72.0%, Avg loss: 1.094438 

Epoch 70
-------------------------------
loss: 1.318507  [   64/74412]
loss: 0.962140  [ 6464/74412]
loss: 0.926321  [12864/74412]
loss: 0.781213  [19264/74412]
loss: 0.929454  [25664/74412]
loss: 1.253736  [32064/74412]
loss: 1.081787  [38464/74412]
loss: 0.708706  [44864/74412]
loss: 0.852826  [51264/74412]
loss: 0.773511  [57664/74412]
loss: 0.850146  [64064/74412]
loss: 0.687679  [70464/74412]
Test Error: 
 Accuracy: 72.5%, Avg loss: 1.065617 

Epoch 71
-------------------------------
loss: 1.288479  [   64/74412]
loss: 0.923325  [ 6464/74412]
loss: 0.930637  [12864/74412]
loss: 0.774485  [19264/74412]
loss: 0.898996  [25664/74412]
loss: 1.205804  [32064/74412]
loss: 1.103930  [38464/74412]
loss: 0.698747  [44864/74412]
loss: 0.840804  [51264/74412]
loss: 0.727175  [57664/74412]
loss: 0.829849  [64064/74412]
loss: 0.680946  [70464/74412]
Test Error: 
 Accuracy: 72.6%, Avg loss: 1.075525 

Epoch 72
-------------------------------
loss: 1.306061  [   64/74412]
loss: 0.952009  [ 6464/74412]
loss: 0.907871  [12864/74412]
loss: 0.748158  [19264/74412]
loss: 0.904302  [25664/74412]
loss: 1.193859  [32064/74412]
loss: 1.091799  [38464/74412]
loss: 0.677653  [44864/74412]
loss: 0.840671  [51264/74412]
loss: 0.771333  [57664/74412]
loss: 0.840850  [64064/74412]
loss: 0.675427  [70464/74412]
Test Error: 
 Accuracy: 72.2%, Avg loss: 1.082152 

Epoch 73
-------------------------------
loss: 1.290767  [   64/74412]
loss: 0.930240  [ 6464/74412]
loss: 0.898921  [12864/74412]
loss: 0.750798  [19264/74412]
loss: 0.879845  [25664/74412]
loss: 1.183868  [32064/74412]
loss: 1.085363  [38464/74412]
loss: 0.672154  [44864/74412]
loss: 0.861670  [51264/74412]
loss: 0.706064  [57664/74412]
loss: 0.822787  [64064/74412]
loss: 0.672820  [70464/74412]
Test Error: 
 Accuracy: 72.5%, Avg loss: 1.061864 

Epoch 74
-------------------------------
loss: 1.274759  [   64/74412]
loss: 0.919045  [ 6464/74412]
loss: 0.890121  [12864/74412]
loss: 0.754607  [19264/74412]
loss: 0.899925  [25664/74412]
loss: 1.205650  [32064/74412]
loss: 1.015272  [38464/74412]
loss: 0.681394  [44864/74412]
loss: 0.844019  [51264/74412]
loss: 0.738542  [57664/74412]
loss: 0.815194  [64064/74412]
loss: 0.656351  [70464/74412]
Test Error: 
 Accuracy: 73.1%, Avg loss: 1.051954 

Epoch 75
-------------------------------
loss: 1.257461  [   64/74412]
loss: 0.920312  [ 6464/74412]
loss: 0.881412  [12864/74412]
loss: 0.729527  [19264/74412]
loss: 0.890937  [25664/74412]
loss: 1.220327  [32064/74412]
loss: 1.035304  [38464/74412]
loss: 0.673239  [44864/74412]
loss: 0.854492  [51264/74412]
loss: 0.682169  [57664/74412]
loss: 0.825131  [64064/74412]
loss: 0.661471  [70464/74412]
Test Error: 
 Accuracy: 72.8%, Avg loss: 1.053165 

Epoch 76
-------------------------------
loss: 1.250450  [   64/74412]
loss: 0.929665  [ 6464/74412]
loss: 0.894520  [12864/74412]
loss: 0.725210  [19264/74412]
loss: 0.904428  [25664/74412]
loss: 1.184147  [32064/74412]
loss: 1.047753  [38464/74412]
loss: 0.669717  [44864/74412]
loss: 0.842014  [51264/74412]
loss: 0.659702  [57664/74412]
loss: 0.803874  [64064/74412]
loss: 0.663496  [70464/74412]
Test Error: 
 Accuracy: 73.2%, Avg loss: 1.043967 

Epoch 77
-------------------------------
loss: 1.236702  [   64/74412]
loss: 0.919481  [ 6464/74412]
loss: 0.869661  [12864/74412]
loss: 0.730918  [19264/74412]
loss: 0.895437  [25664/74412]
loss: 1.187884  [32064/74412]
loss: 1.010656  [38464/74412]
loss: 0.667429  [44864/74412]
loss: 0.852215  [51264/74412]
loss: 0.709396  [57664/74412]
loss: 0.778639  [64064/74412]
loss: 0.650959  [70464/74412]
Test Error: 
 Accuracy: 72.7%, Avg loss: 1.063256 

Epoch 78
-------------------------------
loss: 1.250697  [   64/74412]
loss: 0.915962  [ 6464/74412]
loss: 0.875895  [12864/74412]
loss: 0.719426  [19264/74412]
loss: 0.871825  [25664/74412]
loss: 1.163219  [32064/74412]
loss: 0.997744  [38464/74412]
loss: 0.661522  [44864/74412]
loss: 0.831485  [51264/74412]
loss: 0.690504  [57664/74412]
loss: 0.770660  [64064/74412]
loss: 0.650571  [70464/74412]
Test Error: 
 Accuracy: 74.2%, Avg loss: 1.009458 

Epoch 79
-------------------------------
loss: 1.195453  [   64/74412]
loss: 0.913841  [ 6464/74412]
loss: 0.889714  [12864/74412]
loss: 0.707186  [19264/74412]
loss: 0.909111  [25664/74412]
loss: 1.198234  [32064/74412]
loss: 0.988958  [38464/74412]
loss: 0.669134  [44864/74412]
loss: 0.820441  [51264/74412]
loss: 0.599838  [57664/74412]
loss: 0.782642  [64064/74412]
loss: 0.631924  [70464/74412]
Test Error: 
 Accuracy: 74.1%, Avg loss: 1.010861 

Epoch 80
-------------------------------
loss: 1.202521  [   64/74412]
loss: 0.910259  [ 6464/74412]
loss: 0.884903  [12864/74412]
loss: 0.685110  [19264/74412]
loss: 0.907347  [25664/74412]
loss: 1.176758  [32064/74412]
loss: 0.993633  [38464/74412]
loss: 0.660659  [44864/74412]
loss: 0.821193  [51264/74412]
loss: 0.632820  [57664/74412]
loss: 0.754730  [64064/74412]
loss: 0.629898  [70464/74412]
Test Error: 
 Accuracy: 73.6%, Avg loss: 1.031593 

Epoch 81
-------------------------------
loss: 1.220930  [   64/74412]
loss: 0.917217  [ 6464/74412]
loss: 0.863856  [12864/74412]
loss: 0.686340  [19264/74412]
loss: 0.890423  [25664/74412]
loss: 1.173318  [32064/74412]
loss: 1.019960  [38464/74412]
loss: 0.667407  [44864/74412]
loss: 0.808167  [51264/74412]
loss: 0.605214  [57664/74412]
loss: 0.779599  [64064/74412]
loss: 0.641803  [70464/74412]
Test Error: 
 Accuracy: 72.9%, Avg loss: 1.051543 

Epoch 82
-------------------------------
loss: 1.269769  [   64/74412]
loss: 0.872508  [ 6464/74412]
loss: 0.868420  [12864/74412]
loss: 0.668214  [19264/74412]
loss: 0.882795  [25664/74412]
loss: 1.134169  [32064/74412]
loss: 0.996907  [38464/74412]
loss: 0.650369  [44864/74412]
loss: 0.801898  [51264/74412]
loss: 0.625156  [57664/74412]
loss: 0.763067  [64064/74412]
loss: 0.609104  [70464/74412]
Test Error: 
 Accuracy: 73.7%, Avg loss: 1.021562 

Epoch 83
-------------------------------
loss: 1.219107  [   64/74412]
loss: 0.881426  [ 6464/74412]
loss: 0.837190  [12864/74412]
loss: 0.666365  [19264/74412]
loss: 0.886025  [25664/74412]
loss: 1.154186  [32064/74412]
loss: 0.998078  [38464/74412]
loss: 0.654254  [44864/74412]
loss: 0.806920  [51264/74412]
loss: 0.594122  [57664/74412]
loss: 0.765204  [64064/74412]
loss: 0.617948  [70464/74412]
Test Error: 
 Accuracy: 73.7%, Avg loss: 1.025368 

Epoch 84
-------------------------------
loss: 1.189047  [   64/74412]
loss: 0.878912  [ 6464/74412]
loss: 0.843104  [12864/74412]
loss: 0.678208  [19264/74412]
loss: 0.848861  [25664/74412]
loss: 1.153590  [32064/74412]
loss: 0.981925  [38464/74412]
loss: 0.646757  [44864/74412]
loss: 0.817843  [51264/74412]
loss: 0.619555  [57664/74412]
loss: 0.741270  [64064/74412]
loss: 0.609965  [70464/74412]
Test Error: 
 Accuracy: 74.4%, Avg loss: 1.004723 

Epoch 85
-------------------------------
loss: 1.190720  [   64/74412]
loss: 0.866043  [ 6464/74412]
loss: 0.833694  [12864/74412]
loss: 0.670611  [19264/74412]
loss: 0.873310  [25664/74412]
loss: 1.122724  [32064/74412]
loss: 0.974539  [38464/74412]
loss: 0.665128  [44864/74412]
loss: 0.785622  [51264/74412]
loss: 0.596380  [57664/74412]
loss: 0.740746  [64064/74412]
loss: 0.588858  [70464/74412]
Test Error: 
 Accuracy: 74.2%, Avg loss: 1.006952 

Epoch 86
-------------------------------
loss: 1.171611  [   64/74412]
loss: 0.885926  [ 6464/74412]
loss: 0.855061  [12864/74412]
loss: 0.654052  [19264/74412]
loss: 0.887439  [25664/74412]
loss: 1.132378  [32064/74412]
loss: 0.960188  [38464/74412]
loss: 0.638577  [44864/74412]
loss: 0.797109  [51264/74412]
loss: 0.574268  [57664/74412]
loss: 0.747138  [64064/74412]
loss: 0.598286  [70464/74412]
Test Error: 
 Accuracy: 74.0%, Avg loss: 1.017775 

Epoch 87
-------------------------------
loss: 1.168224  [   64/74412]
loss: 0.852083  [ 6464/74412]
loss: 0.822602  [12864/74412]
loss: 0.643611  [19264/74412]
loss: 0.842100  [25664/74412]
loss: 1.114567  [32064/74412]
loss: 0.962085  [38464/74412]
loss: 0.621709  [44864/74412]
loss: 0.801655  [51264/74412]
loss: 0.584679  [57664/74412]
loss: 0.713743  [64064/74412]
loss: 0.594815  [70464/74412]
Test Error: 
 Accuracy: 73.7%, Avg loss: 1.021386 

Epoch 88
-------------------------------
loss: 1.204123  [   64/74412]
loss: 0.862218  [ 6464/74412]
loss: 0.817872  [12864/74412]
loss: 0.651661  [19264/74412]
loss: 0.860205  [25664/74412]
loss: 1.125986  [32064/74412]
loss: 0.965065  [38464/74412]
loss: 0.628719  [44864/74412]
loss: 0.821450  [51264/74412]
loss: 0.566515  [57664/74412]
loss: 0.712332  [64064/74412]
loss: 0.584822  [70464/74412]
Test Error: 
 Accuracy: 74.0%, Avg loss: 1.016285 

Epoch 89
-------------------------------
loss: 1.163919  [   64/74412]
loss: 0.858457  [ 6464/74412]
loss: 0.813881  [12864/74412]
loss: 0.645926  [19264/74412]
loss: 0.862001  [25664/74412]
loss: 1.080085  [32064/74412]
loss: 0.978427  [38464/74412]
loss: 0.624149  [44864/74412]
loss: 0.779293  [51264/74412]
loss: 0.560063  [57664/74412]
loss: 0.698668  [64064/74412]
loss: 0.572401  [70464/74412]
Test Error: 
 Accuracy: 73.6%, Avg loss: 1.022675 

Epoch 90
-------------------------------
loss: 1.170368  [   64/74412]
loss: 0.831964  [ 6464/74412]
loss: 0.829233  [12864/74412]
loss: 0.643232  [19264/74412]
loss: 0.856744  [25664/74412]
loss: 1.085753  [32064/74412]
loss: 0.968586  [38464/74412]
loss: 0.622329  [44864/74412]
loss: 0.791154  [51264/74412]
loss: 0.552176  [57664/74412]
loss: 0.717150  [64064/74412]
loss: 0.579733  [70464/74412]
Test Error: 
 Accuracy: 74.1%, Avg loss: 1.015714 

Epoch 91
-------------------------------
loss: 1.159176  [   64/74412]
loss: 0.815948  [ 6464/74412]
loss: 0.801914  [12864/74412]
loss: 0.640914  [19264/74412]
loss: 0.889601  [25664/74412]
loss: 1.092165  [32064/74412]
loss: 0.968997  [38464/74412]
loss: 0.622422  [44864/74412]
loss: 0.794016  [51264/74412]
loss: 0.531732  [57664/74412]
loss: 0.683654  [64064/74412]
loss: 0.567105  [70464/74412]
Test Error: 
 Accuracy: 74.1%, Avg loss: 1.020554 

Epoch 92
-------------------------------
loss: 1.162522  [   64/74412]
loss: 0.835737  [ 6464/74412]
loss: 0.812754  [12864/74412]
loss: 0.620372  [19264/74412]
loss: 0.881605  [25664/74412]
loss: 1.043005  [32064/74412]
loss: 0.953558  [38464/74412]
loss: 0.613363  [44864/74412]
loss: 0.758012  [51264/74412]
loss: 0.520548  [57664/74412]
loss: 0.668072  [64064/74412]
loss: 0.571532  [70464/74412]
Test Error: 
 Accuracy: 74.3%, Avg loss: 1.002904 

Epoch 93
-------------------------------
loss: 1.163893  [   64/74412]
loss: 0.810013  [ 6464/74412]
loss: 0.820078  [12864/74412]
loss: 0.635711  [19264/74412]
loss: 0.842178  [25664/74412]
loss: 1.084460  [32064/74412]
loss: 0.961891  [38464/74412]
loss: 0.609013  [44864/74412]
loss: 0.775733  [51264/74412]
loss: 0.541429  [57664/74412]
loss: 0.665842  [64064/74412]
loss: 0.554472  [70464/74412]
Test Error: 
 Accuracy: 74.1%, Avg loss: 1.002406 

Epoch 94
-------------------------------
loss: 1.167852  [   64/74412]
loss: 0.805360  [ 6464/74412]
loss: 0.792635  [12864/74412]
loss: 0.631481  [19264/74412]
loss: 0.851509  [25664/74412]
loss: 1.039808  [32064/74412]
loss: 0.954685  [38464/74412]
loss: 0.597492  [44864/74412]
loss: 0.733300  [51264/74412]
loss: 0.552928  [57664/74412]
loss: 0.684989  [64064/74412]
loss: 0.561374  [70464/74412]
Test Error: 
 Accuracy: 74.3%, Avg loss: 1.001945 

Epoch 95
-------------------------------
loss: 1.155664  [   64/74412]
loss: 0.799702  [ 6464/74412]
loss: 0.792035  [12864/74412]
loss: 0.613814  [19264/74412]
loss: 0.818377  [25664/74412]
loss: 1.043595  [32064/74412]
loss: 0.936246  [38464/74412]
loss: 0.599892  [44864/74412]
loss: 0.745844  [51264/74412]
loss: 0.521765  [57664/74412]
loss: 0.663377  [64064/74412]
loss: 0.554331  [70464/74412]
Test Error: 
 Accuracy: 73.9%, Avg loss: 1.017658 

Epoch 96
-------------------------------
loss: 1.173380  [   64/74412]
loss: 0.816615  [ 6464/74412]
loss: 0.819389  [12864/74412]
loss: 0.618976  [19264/74412]
loss: 0.803557  [25664/74412]
loss: 1.030712  [32064/74412]
loss: 0.955386  [38464/74412]
loss: 0.592731  [44864/74412]
loss: 0.735236  [51264/74412]
loss: 0.531192  [57664/74412]
loss: 0.667283  [64064/74412]
loss: 0.567656  [70464/74412]
Test Error: 
 Accuracy: 73.4%, Avg loss: 1.044529 

Epoch 97
-------------------------------
loss: 1.197873  [   64/74412]
loss: 0.778113  [ 6464/74412]
loss: 0.811462  [12864/74412]
loss: 0.612659  [19264/74412]
loss: 0.844569  [25664/74412]
loss: 1.020370  [32064/74412]
loss: 0.881847  [38464/74412]
loss: 0.590941  [44864/74412]
loss: 0.727413  [51264/74412]
loss: 0.506376  [57664/74412]
loss: 0.674511  [64064/74412]
loss: 0.549767  [70464/74412]
Test Error: 
 Accuracy: 74.5%, Avg loss: 0.993434 

Epoch 98
-------------------------------
loss: 1.129916  [   64/74412]
loss: 0.783800  [ 6464/74412]
loss: 0.799365  [12864/74412]
loss: 0.594707  [19264/74412]
loss: 0.825120  [25664/74412]
loss: 1.008812  [32064/74412]
loss: 0.923251  [38464/74412]
loss: 0.605031  [44864/74412]
loss: 0.721175  [51264/74412]
loss: 0.510955  [57664/74412]
loss: 0.674262  [64064/74412]
loss: 0.547763  [70464/74412]
Test Error: 
 Accuracy: 74.6%, Avg loss: 0.999905 

Epoch 99
-------------------------------
loss: 1.135343  [   64/74412]
loss: 0.803993  [ 6464/74412]
loss: 0.804107  [12864/74412]
loss: 0.582939  [19264/74412]
loss: 0.792120  [25664/74412]
loss: 1.020890  [32064/74412]
loss: 0.908919  [38464/74412]
loss: 0.575457  [44864/74412]
loss: 0.724184  [51264/74412]
loss: 0.508154  [57664/74412]
loss: 0.646980  [64064/74412]
loss: 0.553331  [70464/74412]
Test Error: 
 Accuracy: 73.9%, Avg loss: 1.023252 

Epoch 100
-------------------------------
loss: 1.137538  [   64/74412]
loss: 0.763929  [ 6464/74412]
loss: 0.796385  [12864/74412]
loss: 0.593743  [19264/74412]
loss: 0.787136  [25664/74412]
loss: 0.999560  [32064/74412]
loss: 0.896652  [38464/74412]
loss: 0.583778  [44864/74412]
loss: 0.706400  [51264/74412]
loss: 0.492367  [57664/74412]
loss: 0.657553  [64064/74412]
loss: 0.560776  [70464/74412]
Test Error: 
 Accuracy: 75.1%, Avg loss: 0.980493 

Done!
